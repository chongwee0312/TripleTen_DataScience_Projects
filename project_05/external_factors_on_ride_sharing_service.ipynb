{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a146b38c",
   "metadata": {},
   "source": [
    "# Analysing the Impact of External Factors on Ride Sharing Service"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c0bbde",
   "metadata": {},
   "source": [
    "# Contents <a id='back'></a>\n",
    "* [1. Introduction](#intro)\n",
    "* [2. Data Exploration](#data_exploration)\n",
    "* [3. Data Preprocessing](#data_preprocessing)\n",
    "* [4. Exploratory Data Analysis (EDA)](#eda)\n",
    "    * [Distribution of Trips on 15-16 November by Company](#company_trip)\n",
    "    * [Top 10 Companies in Chicago Ride Sharing Service](#top_10_company)\n",
    "    * [Distribution of Daily Trips by Neighbourhood](#neighbourhood_trip)\n",
    "    * [Top 10 Visited Neighbourhoods in Chicago with Ride Sharing Service ](#top_10_neighbourhood)\n",
    "    * [Number of Trips from Loop to O'hare International Airport on Saturday](#saturday_trip)\n",
    "    * [Average Time Duration from Loop to O'hare International Airport per Weather Condition ](#weather_trip)\n",
    "* [5. Hypothesis Testing](#hypothesis_testing)\n",
    "* [6. General Conclusion](#general_conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1a4cd1",
   "metadata": {},
   "source": [
    "## 1. Introduction <a id='intro'></a>\n",
    "\n",
    "This project is to perform an analysis for a new ride-sharing company which is launching in Chicago. By using available online information and database, relevant analyses will be conducted to understand the passenger preferences and the impact of external factors on rides."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799c695d",
   "metadata": {},
   "source": [
    "### Purpose\n",
    "\n",
    "This project aims to answer the following quesions:\n",
    "1. Which company is the current leader in the ride-sharing service?\n",
    "2. Which location in Chicago is the most popular destination for ride-sharing services?\n",
    "3. Does weather condition have impact on ride-sharing service usage?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03dc9239",
   "metadata": {},
   "source": [
    "### Hypothesis\n",
    "\n",
    "One hypothesis is formulated to test the impact of weather on ride-sharing servive:\n",
    "1. The average duration of rides from the Loop to O'Hare International Airport changes on rainy Saturdays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fb5eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as st\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d69c65",
   "metadata": {},
   "source": [
    "## 2. Data Exploration <a id='data_exploration'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f879fd",
   "metadata": {},
   "source": [
    "The weather data in Chicago in November 2017 is available online, the data has been parsed and uploaded to the company's database. After that, an exploratory data analysis was performed with other information in the database. The outcomes have been exported into three separate datasets and will be used to conduct the relevant analyses and hypothesis testing in this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7726ed20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the three datasets\n",
    "try:\n",
    "    company_data = pd.read_csv('moved_project_sql_result_01.csv')\n",
    "    dropoff_data = pd.read_csv('moved_project_sql_result_04.csv')\n",
    "    trip_data = pd.read_csv('moved_project_sql_result_07.csv')\n",
    "except:\n",
    "    company_data = pd.read_csv('/datasets/moved_project_sql_result_01.csv')\n",
    "    dropoff_data = pd.read_csv('/datasets/moved_project_sql_result_04.csv')\n",
    "    trip_data = pd.read_csv('/datasets/moved_project_sql_result_07.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52464ee",
   "metadata": {},
   "source": [
    "**`company_data`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233aee87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have a look at the company data\n",
    "company_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d60ffb",
   "metadata": {},
   "source": [
    "The dataset has 64 rows (company) and 2 columns of information related to each company.\n",
    "\n",
    "**Description of data**\n",
    "- comapany_name: taxi company name\n",
    "- trips_amount: the number of rides for each taxi company on November 15-16, 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfeef45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there is any missing value\n",
    "company_data.isna().sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697d52b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "company_data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1fc580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the data types\n",
    "company_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5320bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the statictics of the numerical columns\n",
    "company_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c994440f",
   "metadata": {},
   "source": [
    "- No missing value and duplicate, the data type is also correct.\n",
    "- No obvious anomaly in the `trips_amount` column. The mean value is significantly greater than the median, which shows that the distribution of the `trips_amount` data is heavily skewed to the right."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959f535d",
   "metadata": {},
   "source": [
    "**`dropoff_data`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d471dd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have a look at the dropoff data\n",
    "dropoff_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241545fb",
   "metadata": {},
   "source": [
    "The dataset has 94 rows (dropoff location) and 2 columns of information related to each location.\n",
    "\n",
    "**Description of data**\n",
    "- dropoff_location_name: Chicago neighbourhoods where rides ended\n",
    "- average_trips: the average number of rides that ended in each neightbourhood in November 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbbe3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there is any missing value\n",
    "dropoff_data.isna().sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bdc4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "dropoff_data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7eadf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the data types\n",
    "dropoff_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed05a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the statictics of the numerical columns\n",
    "dropoff_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1093c78",
   "metadata": {},
   "source": [
    "- No missing value and duplicate, the data type is also correct.\n",
    "- No obvious anomaly in the `average_trips` column. The mean value is also greater than the median, therefore the distribution of the `trips_amount` data is skewed to the right."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c849652",
   "metadata": {},
   "source": [
    "**`trip_data`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644ace92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have a look at the trip data\n",
    "trip_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3455772",
   "metadata": {},
   "source": [
    "The dataset has 1068 rows (trips) and 3 columns of information related to each trip.\n",
    "\n",
    "**Description of data**\n",
    "- start_ts: pickup date and time\n",
    "- weather_conditions: weather conditions at the moment the ride started\n",
    "- duration_seconds: ride duration in seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e45750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there is any missing value\n",
    "trip_data.isna().sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0064c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "trip_data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344952fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the data types\n",
    "trip_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26237f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the statictics of the numerical columns\n",
    "trip_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a26c15",
   "metadata": {},
   "source": [
    "- There is no missing values in the `trip_data`\n",
    "- The data type of `start_ts` should be `datetime` and there are 197 duplicated rows.\n",
    "- It is impossible to have a minimum value of `0` second time duration. We will further investigate into this issue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea06377f",
   "metadata": {},
   "source": [
    "**Conclusion**\n",
    "\n",
    "From the overview of the data, the dataset are sufficient to conduct the relevant analysis and test the hypotheses. However, there are\n",
    "\n",
    "**Issues need to be addresed later**\n",
    "- Change the data type of `start_ts` to `datetime`.\n",
    "- Investigate into the 197 duplicated rows and the anomalies of `0` second ride duration in `trip_data`.\n",
    "\n",
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa836c6",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing <a id='data_preprocessing'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59144569",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b9529f",
   "metadata": {},
   "source": [
    "The following function will assist in automating the works in data preprocessing and exploratory data analysis stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3316b0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sns_histplot(data, x, figsize, title, xlabel, ylabel, bins, xticks_label):\n",
    "    \"\"\"\n",
    "    This function plots a histogram to show the distribution of a dataset\n",
    "    \"\"\"\n",
    "    # Set up figure\n",
    "    sns.set_style('whitegrid')\n",
    "    plt.figure(figsize = (figsize[0], figsize[1]))    \n",
    "    \n",
    "    # Plot the histogram\n",
    "    sns.histplot(data = data, x = x, color = 'red', bins = bins)\n",
    "    \n",
    "    # Set title, xlabel, ylabel, xticks\n",
    "    plt.title(title, fontsize = 14, fontweight = 'bold', color = 'blue')\n",
    "    plt.xlabel(xlabel, fontsize = 12, fontweight = 'bold')\n",
    "    plt.ylabel(ylabel, fontsize = 12, fontweight = 'bold')\n",
    "    plt.xticks(xticks_label, fontweight = 'bold')\n",
    "    plt.yticks(fontweight = 'bold')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244e941c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45c6f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the data type of start_ts to date time\n",
    "trip_data['start_ts'] = pd.to_datetime(trip_data['start_ts'], format = '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Check if the data type of start_ts is updated\n",
    "trip_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54ab8da",
   "metadata": {},
   "source": [
    "Next, we will have an investigation on the duplicated rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62f3299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have a look at some of the duplicated rows\n",
    "trip_data[trip_data.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6956cf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the first dupliacted record\n",
    "trip_data.query('start_ts == \"2017-11-11 06:00:00\" and duration_seconds == 1260')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7062d338",
   "metadata": {},
   "source": [
    "These 'duplicated' rows are suspected to be different trip records since the time records in `start_ts` were rounded to the nearest hour and the `duration_seconds` are divisible by 60, indicating that the durations were rounded to the nearest minute. We will keep these duplicates as we do not have enough evidence to prove that they are duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6568b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a histogram to show the distribution of duration_seconds\n",
    "sns_histplot(data = trip_data, x = 'duration_seconds', figsize = (7,4),\n",
    "             title = 'Distribution of Time Duration from Loop to O\\'hare International Airport',\n",
    "             xlabel = 'Time (second)', ylabel = 'Number of Trips',\n",
    "             bins = [x for x in np.arange(0,7500,500)], \n",
    "             xticks_label = [x for x in np.arange(0,7500,500)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb3f7f3",
   "metadata": {},
   "source": [
    "From the histogram, the trips with travel time less than 1000 seconds obviously are anomalies. Let's check the percentages of the anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d197c187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the trips with travel time less than 1000 seconds\n",
    "trip_data.query('duration_seconds < 1000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93690302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentage of anomalies with low values of travel time\n",
    "print('The percentage of trips with travel time less than 500 seconds:',\n",
    "      f'{trip_data.query(\"duration_seconds < 1000\").shape[0] / trip_data.shape[0]:.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b615da6e",
   "metadata": {},
   "source": [
    "The percentage of anomalies account about 1% of the whole dataset and they will be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badb0d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the rows with anomalies\n",
    "trip_data = trip_data.query('duration_seconds >= 1000')\n",
    "\n",
    "# Last check on the info of the trip_data\n",
    "trip_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ba693a",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20023c27",
   "metadata": {},
   "source": [
    "## 4. Exploratory Data Analysis (EDA) <a id='eda'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b53a63",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9128f07",
   "metadata": {},
   "source": [
    "The following functions will automate the works in the exploratory data analysis stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea88bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_top_groups(data, row, factor):\n",
    "    \"\"\"\n",
    "    This function assign groups according to the descending order of a\n",
    "    specific ranking factor\n",
    "    \"\"\"\n",
    "    # Create a list to identify the ranking\n",
    "    ranking_list = list(data.sort_values(factor, ascending = False)[factor])\n",
    "    \n",
    "    # Assign group according to the ranking list\n",
    "    if row[factor] in ranking_list[0:10]:    \n",
    "        return 'Top 10'\n",
    "    elif row[factor] in ranking_list[10:20]:\n",
    "        return 'Top 11-20'\n",
    "    else:\n",
    "        return 'Others'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d1635b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_10_plot(data, x, y, group, figsize, suptitle, pie_title, bar_title, bar_xlabel, bar_ylabel):\n",
    "    \"\"\"\n",
    "    This function creates a pie chart to show the percentage in each group\n",
    "    and a bar chart to show the distribution in top 10 based on a factor\n",
    "    \"\"\"\n",
    "    # Create data for the charts\n",
    "    pie_data = data.groupby(group)[y].sum().sort_values()\n",
    "    bar_data = data.sort_values(y, ascending = False).head(10)\n",
    "    \n",
    "    # Set up figure\n",
    "    sns.set_style('white')\n",
    "    sns.set_palette('Set2')\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize = (figsize[0], figsize[1]))    \n",
    "    \n",
    "    # Plot the pie chart and the bar chart\n",
    "    ax1.pie(pie_data.values, labels = pie_data.index, autopct = '%1.1f%%',\n",
    "            startangle = 90, shadow = True, explode = (0, 0, 0.1))\n",
    "    ax1.axis('equal')\n",
    "    sns.barplot(data = bar_data, x = y, y = x, ax = ax2)\n",
    "    \n",
    "    # Set suptitle, titles, labels\n",
    "    fig.suptitle(suptitle, fontsize = 14, fontweight = 'bold', color = 'darkblue', x = 0.66)\n",
    "    ax1.set_title(pie_title, fontsize = 12, fontweight = 'bold', y = 1.04, color = 'blue')\n",
    "    ax2.set_title(bar_title, fontsize = 12, fontweight = 'bold', color = 'blue')\n",
    "    ax2.set_xlabel(bar_xlabel, fontweight = 'bold')\n",
    "    ax2.set_ylabel(bar_ylabel, fontweight = 'bold')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52377eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sns_barplot(data, x, y, hue, agg, figsize, title, xlabel, ylabel, xticks_label):\n",
    "    \"\"\"\n",
    "    This function plot a bar chart to \n",
    "    compare the values in column (y) based on other columns (x)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create an aggregated data\n",
    "    data = data.groupby([x, hue])[y].agg(agg).reset_index()    \n",
    "    data.columns = [x, hue, agg]\n",
    "    \n",
    "    # Set up figure\n",
    "    sns.set_style('whitegrid')\n",
    "    sns.set_palette('deep')\n",
    "    plt.figure(figsize = (figsize[0], figsize[1]))\n",
    "    \n",
    "    # Plot the bar chart\n",
    "    sns.barplot(data = data, x = x, y = agg, hue = hue)\n",
    "    \n",
    "    # Set title, labels, ticks, legend\n",
    "    plt.title(title, fontsize = 14, fontweight = 'bold', color = 'blue')\n",
    "    plt.xlabel(xlabel, fontsize = 12, fontweight = 'bold')\n",
    "    plt.ylabel(ylabel, fontsize = 12, fontweight = 'bold')\n",
    "    plt.xticks(np.arange(len(xticks_label)), labels = xticks_label, fontweight = 'bold')\n",
    "    plt.yticks(fontweight = 'bold')\n",
    "    plt.legend(loc = 'upper left', bbox_to_anchor = (1,1))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7512b531",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9cde60",
   "metadata": {},
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33da61a9",
   "metadata": {},
   "source": [
    "### Distribution of Trips on 15-16 November by Company <a id='company_trip'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521150d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a histogram to show the distribution of number of trips per comapany\n",
    "sns_histplot(data = company_data, x = 'trips_amount', figsize = (7,4),\n",
    "             title = 'Distribution of Trips on 15-16 November by Company',\n",
    "             xlabel = 'Number of Trips', ylabel = 'Number of Companies',\n",
    "             bins = [x for x in np.arange(0,20000,1000)], \n",
    "             xticks_label = [x for x in np.arange(0,20000,2000)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b1800a",
   "metadata": {},
   "source": [
    "From the histogram, it can be seen that the distribution of trips by company indeed skewed heavily to the right. Many companies had very low trip counts and there were a few companies with trip counts of 10000 and above. Let's identify these top leaders in the Chicago ride-sharing service.\n",
    "\n",
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd712125",
   "metadata": {},
   "source": [
    "### Top 10 Companies in Chicago Ride Sharing Service <a id='top_10_company'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ef9be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the top 10 companies\n",
    "company_data.sort_values('trips_amount', ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd85b790",
   "metadata": {},
   "source": [
    "The table shows the top 10 companies with the 'Flash Cab' company be the sole leader in the market. Now, let's examine the performance of the remaining companies in the market."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2cdb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to rank the companies in terms of trips amount\n",
    "company_data['ranking'] = company_data.apply(\n",
    "    lambda x: assign_top_groups(company_data, x, 'trips_amount'), axis = 1\n",
    ")\n",
    "\n",
    "# Check the newly added column\n",
    "company_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bf5063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a pie chart and bar chart to show the distribution of trips in top companies\n",
    "top_10_plot(data = company_data, x = 'company_name', y = 'trips_amount', \n",
    "            group = 'ranking', figsize = (7,5), suptitle = 'Trips on 15-16 November',\n",
    "            pie_title = 'Percentages in Top Companies', bar_title = 'Top 10 Companies',\n",
    "            bar_xlabel = 'Number of Trips', bar_ylabel = 'Company')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50af4faf",
   "metadata": {},
   "source": [
    "The pie chart shows that the top 10 companies account for 72.3% of the total number of trips. The rest of the companies are not matched for these top leaders.\n",
    "\n",
    "Among the the 10 companies, the 'Flash Cab' stands out as the preferred ride-sharing service provider among passengers.\n",
    "\n",
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49903457",
   "metadata": {},
   "source": [
    "### Distribution of Daily Trips by Neighbourhood <a id='neighbourhood_trip'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8120322e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a histogram to show the distribution of number of trips per neighbourhood\n",
    "sns_histplot(data = dropoff_data, x = 'average_trips', figsize = (7,4),\n",
    "             title = 'Distribution of Daily Trips by Neighbourhood',\n",
    "             xlabel = 'Number of Trips', ylabel = 'Number of Neighbourhoods',\n",
    "             bins = [x for x in np.arange(0,12000,500)], \n",
    "             xticks_label = [x for x in np.arange(0,12000,2000)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc00039c",
   "metadata": {},
   "source": [
    "The distribution of daily trips by neighbourhood is also skewed to the right. In Novembery 2017, the majority of neighborhoods recorded a low number of daily trips, while a small number of neighbourhoods had more than 4000 trips per day.\n",
    "\n",
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccb2873",
   "metadata": {},
   "source": [
    "### Top 10 Visited Neighbourhoods in Chicago with Ride Sharing Service <a id='top_10_neighbourhood'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb06ad3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the top 10 neighbourhoods\n",
    "dropoff_data.sort_values('average_trips', ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75056b4",
   "metadata": {},
   "source": [
    "The table above shows the top 10 neighbourhoods in terms of daily trips. The 'Loop' and 'River North' stand out as the most visited neighbourhoods with about 10000 daily trips. Let's find out how the number of trips are distributed in other neighbourhoods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a73e00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to rank the neighbourhood in terms of average_trips\n",
    "dropoff_data['ranking'] = dropoff_data.apply(\n",
    "    lambda x: assign_top_groups(dropoff_data, x, 'average_trips'), axis = 1\n",
    ")\n",
    "\n",
    "# Check the newly added column\n",
    "dropoff_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8c0620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a pie chart and bar chart to show the distribution of trips in top neighbourhoods\n",
    "top_10_plot(data = dropoff_data, x = 'dropoff_location_name', y = 'average_trips', \n",
    "            group = 'ranking', figsize = (5,5), suptitle = 'Daily Trips in November 2017',\n",
    "            pie_title = 'Percentages in Top Neighbourhoods', bar_title = 'Top 10 Neighbourhoods',\n",
    "            bar_xlabel = 'Number of Trips', bar_ylabel = 'Neighbourhood')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fdedcb",
   "metadata": {},
   "source": [
    "In november 2007, top 10 neighbourhoods accounted for 76.7% of daily trips, while the neighbourhoods ranking from 11th to 20th had 14.1%. The remaining 9.2% of trips were spread across the remaining 74 neighbourhoods.\n",
    "\n",
    "Among the top 10 neighbourhoods, the daily trip counts of 'Loop', 'River North', 'Streeterville' and 'West Loop' were at least  double those of the remaining six neighbourhoods.\n",
    "\n",
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b02927",
   "metadata": {},
   "source": [
    "### Number of Trips from Loop to O'hare International Airport on Saturday <a id='saturday_trip'></a>\n",
    "\n",
    "Before testing the hypothesis, we will explore some additional information of `duration_seconds` based on `weather_conditions`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c2b466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column containing the day value of datetime\n",
    "trip_data['day_of_month'] = trip_data['start_ts'].dt.day\n",
    "\n",
    "# Have a look at the column\n",
    "trip_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be90ae84",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns_barplot(data = trip_data, x = 'day_of_month', y = 'duration_seconds', \n",
    "            hue = 'weather_conditions', agg = 'count', figsize = (6,4),\n",
    "            title = 'Number of Trips From Loop to O\\'Hare International Airport on Saturday',\n",
    "            xlabel = 'Date', ylabel = 'Number of Trips', \n",
    "            xticks_label = ['4 Nov', '11 Nov', '18 Nov', '25 Nov'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17bc789",
   "metadata": {},
   "source": [
    "The bar chart reveals that trip counts do not have a regular pattern on Saturdays. Specifically, there were more trips during the first two weekends of November 2017. \n",
    "\n",
    "On the other hand, on November 4, trip count was higher when the weather condition was good. However, on November 18, trip count in bad weather condition was surprisingly higher than that in good weather condition.\n",
    "\n",
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23165c03",
   "metadata": {},
   "source": [
    "### Average Time Duration from Loop to O'hare International Airport per Weather Condition <a id='weather_trip'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cae41b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns_barplot(data = trip_data, x = 'day_of_month', y = 'duration_seconds', \n",
    "            hue = 'weather_conditions', agg = 'mean', figsize = (6,4),\n",
    "            title = 'Average Time Duration From Loop to O\\'Hare International Airport',\n",
    "            xlabel = 'Date', ylabel = 'Time (second)', \n",
    "            xticks_label = ['4 Nov', '11 Nov', '18 Nov', '25 Nov'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e466d2",
   "metadata": {},
   "source": [
    "From the bar chart, the average travel time is around 1800 to 2700 seconds. When comparing travel times on the 4th and 18th of November, the travel time during bad weather was slightly longer. However, on the 18th of November, the difference in travel times between good and bad weather conditions was not significant.\n",
    "\n",
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91465c21",
   "metadata": {},
   "source": [
    "## 5. Hypothesis Testing <a id='hypothesis_testing'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b50e34",
   "metadata": {},
   "source": [
    "### Hypothesis: The average duration of rides from the Loop to O'Hare International Airport changes on rainy Saturdays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231252c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice the trip data based on good and bad weather condtions\n",
    "good_weather_trip = trip_data.query('weather_conditions == \"Good\"').reset_index(drop = True)\n",
    "bad_weather_trip = trip_data.query('weather_conditions == \"Bad\"').reset_index(drop = True)\n",
    "\n",
    "# Display the first three rows of each table\n",
    "display(good_weather_trip.head(3))\n",
    "display(bad_weather_trip.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ec814b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate necessary descriptive statistics\n",
    "count_good = good_weather_trip['duration_seconds'].count()\n",
    "mean_good = np.mean(good_weather_trip['duration_seconds'])\n",
    "var_good = np.var(good_weather_trip['duration_seconds'], ddof=1)\n",
    "std_good = np.std(good_weather_trip['duration_seconds'], ddof=1)\n",
    "    \n",
    "count_bad = bad_weather_trip['duration_seconds'].count()\n",
    "mean_bad = np.mean(bad_weather_trip['duration_seconds'])\n",
    "var_bad = np.var(bad_weather_trip['duration_seconds'], ddof=1)\n",
    "std_bad = np.std(bad_weather_trip['duration_seconds'], ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c320cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the results\n",
    "print('For the duration of rides in good weather condition:')\n",
    "print()\n",
    "print(f'Count: {count_good}')\n",
    "print(f'Mean: {mean_good:.2f}')\n",
    "print(f'Variance: {var_good:.4f}')\n",
    "print(f'Standard Deviation: {std_good:.4f}')\n",
    "print('-'*60)\n",
    "print()\n",
    "print('For the duration of rides in bad weather condition:')\n",
    "print()\n",
    "print(f'Count: {count_bad}')\n",
    "print(f'Mean: {mean_bad:.2f}')\n",
    "print(f'Variance: {var_bad:.4f}')\n",
    "print(f'Standard Deviation: {std_bad:.4f}')\n",
    "print('-'*60)\n",
    "print()\n",
    "print(f'Ratio of variances: {var_good /var_bad:.4f}')   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f054fd",
   "metadata": {},
   "source": [
    "Let the population mean of duration of rides in good weather condition be \\$\\mu_{1}$\n",
    "\n",
    "Let the population mean of duration of rides in bad weather condition be \\$\\mu_{2}$\n",
    "\n",
    "**Sample 1: Trips During Good Weather Condition**\n",
    "- Number of observations: \\$n_{1} \\= 880$\n",
    "\n",
    "- Mean of duration of rides: \\$\\bar{x}_{1} \\= 2017.31$\n",
    "\n",
    "- Standard deviation of duration of rides: \\$s_{1} \\= 739.5286$\n",
    "\n",
    "**Sample 2: Trips During Bad Weather Condition**\n",
    "- Number of observations: \\$n_{2} \\= 178$\n",
    "\n",
    "- Mean of duration of rides: \\$\\bar{x}_{2} \\= 2449.08$\n",
    "\n",
    "- Standard deviation of duration of rides: \\$s_{2} \\= 692.8731$\n",
    "\n",
    "\\$H_{0}: \\mu_{1} \\= \\mu_{2}\\$\n",
    "\n",
    "\\$H_{1}: \\mu_{1} \\ne \\mu_{2}\\$\n",
    "\n",
    "The two samples are independent and we are testing if their means differ, a **two-sample independent t-test** will be performed.\n",
    "\n",
    "To perform a two-sample independent t-test, it is assumed that both samples follow a normal distribution.Hence, a histogram will be plotted for each sample to check the normality.\n",
    "\n",
    "The ratio of the the sample variances is 1.1327, it is likely that we can assume their variances are equal. A **Levene's test** will be conducted before we make a conclusion.\n",
    "\n",
    "To test this hypothesis, it is decided to take a significance level of 0.05\n",
    "\n",
    "Significance level: \\$\\alpha \\= 0.05$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6dd0485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a histogram to show the distribution of duration_seconds for good weather\n",
    "sns_histplot(data = good_weather_trip, x = 'duration_seconds', figsize = (7,4),\n",
    "             title = 'Distribtution of Time Duration from Loop to O\\'hare International Airport (Good Weather)',\n",
    "             xlabel = 'Time (second)', ylabel = 'Number of Trips',\n",
    "             bins = [x for x in np.arange(0,7500,200)], \n",
    "             xticks_label = [x for x in np.arange(0,7500,800)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b66684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a histogram to show the distribution of duration_seconds for bad weather\n",
    "sns_histplot(data = bad_weather_trip, x = 'duration_seconds', figsize = (7,4),\n",
    "             title = 'Distribution of Time Duration from Loop to O\\'hare International Airport (Bad Weather)',\n",
    "             xlabel = 'Time (second)', ylabel = 'Number of Trips',\n",
    "             bins = [x for x in np.arange(0,7500,200)],\n",
    "             xticks_label = [x for x in np.arange(0,7500,800)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c375c1",
   "metadata": {},
   "source": [
    "The distributions of data of the two samples are not perfectly normal, some values between 1200 to 1800 distort the distribution. However, with a large sample size of more than 30, by utilising central limit theorem, the sample mean distribution tends to be normal and t-test can be applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6118464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test if the two variances are different\n",
    "# Take a significance level of 0.01\n",
    "st.levene(good_weather_trip['duration_seconds'],\n",
    "          bad_weather_trip['duration_seconds'],\n",
    "          center = 'median')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344e17a6",
   "metadata": {},
   "source": [
    "The null hypothesis for Lenene's test is that the variances are equal for the two samples. \n",
    "\n",
    "**By taking a significance level of 0.05, a p-value of 0.6374 is higher than the signficance level, we failed to reject the null hypothesis and we assume that the variances are equal.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded81a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conduct t test to test if the means differ\n",
    "alpha = 0.05\n",
    "\n",
    "result = st.ttest_ind(good_weather_trip['duration_seconds'],\n",
    "                      bad_weather_trip['duration_seconds'])\n",
    "\n",
    "print('p_value:', result.pvalue)\n",
    "\n",
    "if result.pvalue < alpha:\n",
    "    print('We reject the null hypothesis.')\n",
    "else:\n",
    "    print('We fail to to reject the null hypothesis.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490923ef",
   "metadata": {},
   "source": [
    "**Since the p-value of 1.36e-12 is lower than the significance level of 0.05, we reject the null hypothesis \\$H_{0}$. We have enough evidence to conclude that the durations of rides during the good weather and the bad weather are significantly different.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9069d88",
   "metadata": {},
   "source": [
    "## 6. General Conclusion <a id='general_conclusion'></a>\n",
    "**Data Exploration**\n",
    "\n",
    "By using the available online weather information and the company database, the dataset are sufficient to conduct the relevant analysis and test the hypotheses. However, there are several issues needed to be adrresed:\n",
    "\n",
    "- The data type of `start_ts` is incorrect.\n",
    "- There are 197 duplicated rows and anomalies in `trip_data`.\n",
    "\n",
    "**Data Cleaning**\n",
    "- The data type of `start_ts` was changed to `datetime`.\n",
    "- The 197 duplicated rows are not duplicates.\n",
    "- The anomalies of `0` in `duration_seconds` were dropped.\n",
    "\n",
    "**Exploratory Analysis**\n",
    "\n",
    "Some valuable findings are:\n",
    "- The top 10 companies account for 72.3% of the total number of trips. The top company is 'Flash Cab'.\n",
    "- The top 10 neighbourhoods accounted for 76.7% of daily trips. The top four neighbourhoods are 'Loop', 'River North', 'Streeterville' and 'West Loop'.\n",
    "- The number of trips do not show a particular pattern on Saturdays.\n",
    "\n",
    "**Hypothesis testing**\n",
    "\n",
    "Hypothesis: The average duration of rides from the Loop to O'Hare International Airport changes on rainy Saturdays.\n",
    "\n",
    "\\$H_{0}: \\mu_{1} \\= \\mu_{2}\\$\n",
    "\n",
    "\\$H_{1}: \\mu_{1} \\ne \\mu_{2}\\$\n",
    "\n",
    "Significance level: \\$\\alpha \\= 0.05$\n",
    "\n",
    "After conducting the statistical test - two-sample independent t-test, we have the following result:\n",
    "\n",
    "**Since the p-value of 1.36e-12 is lower than the significance level of 0.05, we reject the null hypothesis \\$H_{0}$. We have enough evidence to conclude that the durations of rides during the good weather and the bad weather are significantly different.**\n",
    "\n",
    "[Back to Contents](#back)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
